# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KwHcrj6waTeUkA8uTvU9bjmSD6YHZCer

# Predictive Project: Forecasting BBRI Stock
- Nama: Mohammad Valeriant Qumara Tanda
- ID: MC180D5Y0566
- Email: valenttanda@gmail.com

## Import library
Import library yang dibutuhkan untuk proyek ini. Pada proyek ini, akan menggunakan library berikut:
- `pandas`: Mengolah data.
- `numpy`: Melakukan operasi matematika.
- `matplotlib`: Membuat grafik.
- `seaborn`: Untuk membuat grafik yang lebih menarik.
- `tensorflow`: Membuat model neural network yang digunakan untuk prediksi.
- `scikit-learn`: Membuat model machine learning yang digunakan untuk prediksi (untuk kasus ini, tidak digunakan karena menggunakan tensorflow). scikit-learn hanya digunakan pada proses preprocessing dan evaluasi model.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error

"""## Load Dataset
Mengambil dataset dari sumber yang telah ditentukan. Dataset yang digunakan dalam proyek ini adalah dataset yang diambil dari laman [Yahoo Finance](https://finance.yahoo.com/quote/BBRI.JK/) yang berisi data harga saham PT. Bank Rakyat Indonesia (Persero) Tbk pada 5 tahun terakhir dengan menggunakan teknik ETL (_Extract, Transform, Load_).
"""

df = pd.read_csv('BBRI_Stock.csv', sep=',', parse_dates=['Date'], index_col='Date', header=0)
df

"""## EDA
Di tahap ini, akan dilakukan analisis exploratory data (EDA) untuk memahami data yang ada. EDA ini bertujuan untuk memahami distribusi data, hubungan antar variabel, dan menemukan pola-pola yang ada dalam data. Berikut adalah langkah-langkah yang dilakukan pada tahap EDA:

### 1. Dataset information
Berisikan informasi mengenai dataset yang digunakan. Informasi ini meliputi:
- Bentuk dataset: Mengetahui jumlah kolom dan baris dalam dataset
- Informasi dataset: Mengetahui jenis data yang ada dalam dataset, seperti numerik, kategori, atau tanggal, dan secara tidak langsung mengetahui adakah nilai yang hilang dalam dataset atau tidak
- Statistik dataset: Mengetahui nilai rata-rata, median, dan modus dari dataset

Cek Bentuk Dataset
"""

df.shape

"""Cek Informasi Dataset"""

df.info()

"""Handling dataset:
- Drop column: Unnamed:  <br>
Alasan: Kolom ini tidak memiliki informasi yang relevan untuk analisis.

Cek Statistik Dataset
"""

df.describe()

"""Cek Duplikasi Dataset"""

print(f"Duplicated data: {df.duplicated().sum()}")

"""### 2. Handling dataset:
Karena dataset yang digunakan sudah bersih, maka penanganan dataset hanya menghapus kolom yang tidak relevan untuk analisis mendatang.

1. Drop column: Unnamed: 0
"""

df = df.drop(columns=['Unnamed: 0'])
df.info()

"""### 3.  Data Visualization
Visualisasi data dilakukan untuk memahami pola dan tren data. Dalam proyek ini, saya menggunakan library `matplotlib` dan `seaborn` untuk membuat grafik yang menampilkan distribusi nilai-nilai data, serta hubungan antara variabel-variabel. Sebelum melakukan visualisasi, pastikan hanya data numerik yang digunakan.

Memastikan hanya data numerik yang digunakan untuk visualisasi
"""

numerical = df.select_dtypes(include=np.number)
numerical

"""**Correlation between features** <br>
Mengecek korelasi antar fitur numerik dapat membantu dalam menemukan hubungan antara fitur-fitur tersebut. Dengan menggunakan metode korelasi, kita dapat mengetahui apakah ada hubungan antara fitur-fitur tersebut yang dapat membantu dalam proses klasifikasi.
"""

sns.heatmap(numerical.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.show()

"""Stock over time<br>
Mengecek arah pergerakan harga saham berdasarkan Open, High, Low, dan Close selama 5 tahun terakhir
"""

plt.figure(figsize=(10,6))
for col in numerical:
  sns.lineplot(data=df, x='Date', y=col)
  plt.title(f"{col} line plot")
  plt.show()

"""Histogram<br>
Mengecek distribusi data numerik untuk melihat persebaran data, dan menghitung kemiringan distribusi dengan `scipy`
"""

from scipy.stats import skew
sns.set(style="darkgrid")
plt.figure(figsize=(14,8))
numerical.hist(figsize=(14,8), bins=20)
plt.suptitle("Histogram Plot of Numerical Columns", y=1.02)
plt.show()

# Skewness Count
for column in numerical:
  if (df[column].dtype == 'object') or (df[column].nunique() == 2):
    continue
  print(f"Skewness {column}: {skew(df[column]).round(3)}")

"""Pairplot<br>
Melihat persebaran data dari 2 fitur berbeda
"""

sns.pairplot(numerical, diag_kind='kde')
plt.show()



"""Boxplot<br>
Mengetahui rata-rata persebaran data dan mengecek adakah outlier pada suatu data atau tidak
"""

for col in numerical:
  print(f"Statistics for column {col}: \n", df[col].describe)
  plt.figure(figsize=(13,6))
  sns.boxplot(x=df[col])
  plt.title(f'{col} boxplot')
  plt.show()

"""## Preprocessing
Di tahap ini, data yang telah dikumpulkan akan diolah dan disiapkan untuk digunakan dalam model. Tahap ini meliput **Normalization** dan **Sliding Windowing**

Menyalin dataset awal ke dataset untuk preprocessing
"""

df_preprocessed = df.copy()

"""### 1. Normalization
Normalisasi semua data numerik dengan menggunakan fungsi `StandardScaler` dari library `sklearn.preprocessing`. Ini akan mengubah skala data menjadi standar (0-1), sehingga nilai-nilai dapat dibandingkan secara lebih akurat.
"""

# Normalize the 'Close' column using MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))

# Reshape the 'Close' column to 2D as required by MinMaxScaler
close_data = df_preprocessed['Close'].values.reshape(-1, 1)

# Fit and transform the data
close_scaled = scaler.fit_transform(close_data)

# Add the scaled data back to the DataFrame (optional, for reference)
df_preprocessed['Close_scaled'] = close_scaled

# Verify the scaling
print("Original Close range:", df_preprocessed['Close'].min(), "to", df_preprocessed['Close'].max())
print("Scaled Close range:", df_preprocessed['Close_scaled'].min(), "to", df_preprocessed['Close_scaled'].max())

"""### 2. Sliding Windowing
Melakukan teknik sliding windowing untuk mempercepat proses pengolahan data. Teknik ini melibatkan penggunaan jendela yang bergerak untuk memproses data secara berkelompok. Selain itu, tahap ini juga memisahkan data menjadi data latih dan data uji dengan proporsi 80:20
"""

# Function to create sequences for supervised learning
def create_sequences(data, lookback=60):
    X, y = [], []
    for i in range(len(data) - lookback):
        X.append(data[i:i + lookback])  # Sequence of 'lookback' time steps
        y.append(data[i + lookback])    # Next time step
    return np.array(X), np.array(y)

# Prepare the scaled data
lookback = 60  # Number of past days to use for prediction
data_scaled = df_preprocessed['Close_scaled'].values  # Use the scaled data
X, y = create_sequences(data_scaled, lookback)

# Split into train and test sets (e.g., 80% train, 20% test)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Reshape X for LSTM [samples, time steps, features]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

"""## Modeling
Di tahap ini, data yang telah melalui preprocessing dan dipisah menjadi data latih dan data uji, kemudian digunakan untuk membuat dan melatih model forecasting. Model yang digunakan adalah model **LSTM** dan **MLP**.

### 1. LSTM Model
Long-Short Term Memory (LSTM) adalah model yang digunakan untuk memprediksi nilai yang akan datang dari data waktu. LSTM dapat digunakan untuk memprediksi nilai yang akan datang dari data waktu dengan menggunakan informasi dari beberapa waktu yang lalu. Hal yang dikerjakan untuk membuat model LSTM adalah sebagai berikut:
1. Pembuatan arsitektur model LSTM
2. Melatih model LSTM
3. Menguji model LSTM
4. Hasil evaluasi model LSTM dengan RMSE, MAE, dan MAPE
5. Visualisasi hasil prediksi dari model LSTM terhadap nilai aktual

1. Membuat arsitektur model
"""

# LSTM Model
model_lstm = Sequential([
  LSTM(100, return_sequences=True, input_shape=(lookback, 1)),
  Dropout(0.2),
  LSTM(100),
  Dense(50, activation='relu'),
  Dropout(0.2),
  BatchNormalization(),
  Dense(1)
])
model_lstm.summary()

"""2. Fungsi callback untuk menghentikan proses pelatihan ketika model mencapai akurasi tertinggi"""

# Callback
callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
            tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)]

"""3. Melatih model"""

model_lstm.compile(loss='mae', optimizer='adam', metrics=["mae"])
history_lstm = model_lstm.fit(X_train, y_train, epochs=100, callbacks=callback, batch_size=32, validation_split=0.1, verbose=1)

"""#### Model Evaluation
Di tahap ini, model yang telah dilatih akan di uji dengan data uji. Dari hasil pengujian, selanjutnya model dievaluasi dengan menggunakan beberapa metrik evaluasi, yaitu RMSE, MAE, dan MAPE

Prediction<br>
Menguji hasil pelatihan model dengan data uji
"""

# Predict on test set
pred_lstm_scaled = model_lstm.predict(X_test)

# Inverse-transform the predictions and actual values
y_test_2d = y_test.reshape(-1, 1)  # Ensure 2D shape for scaler
pred_lstm_2d = pred_lstm_scaled.reshape(-1, 1)

y_test_unscaled = scaler.inverse_transform(y_test_2d)
pred_lstm_unscaled = scaler.inverse_transform(pred_lstm_2d)

# Flatten for consistency
y_test_unscaled = y_test_unscaled.flatten()
pred_lstm_unscaled = pred_lstm_unscaled.flatten()

"""Evaluation<br>
Mengukur hasil uji model dengan metrik RMSE, MAE, dan MAPE
"""

rmse_lstm_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, pred_lstm_unscaled))
mae_lstm_unscaled = mean_absolute_error(y_test_unscaled, pred_lstm_unscaled)
mape_lstm_unscaled = mean_absolute_percentage_error(y_test_unscaled, pred_lstm_unscaled) * 100
print(f"RMSE: {rmse_lstm_unscaled:.4f}")
print(f"MAE: {mae_lstm_unscaled:.4f}")
print(f"MAPE: {mape_lstm_unscaled:.4f}%")

"""Visualization<br>
Visualisasi hasil uji model terhadap nilai aktual
"""

plt.figure(figsize=(14, 6))
plt.plot(y_test_unscaled[:300], label="Actual Data (Close)")
plt.plot(pred_lstm_unscaled[:300], label="LSTM Prediction", linestyle='--')
plt.title("LSTM: Prediction vs Actual Data (Close)")
plt.xlabel("Time")
plt.ylabel("Close")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### 2. MLP Model

MultiLayer Perceptron (MLP) adalah model yang paling umum digunakan dalam deep learning. MLP terdiri dari beberapa layer yang masing-masing terdiri dari beberapa neuron. Setiap neuron memiliki beberapa input dan output. Hal yang dikerjakan untuk membuat model MLP adalah sebagai berikut:
1. Pembuatan arsitektur model MLP
2. Melatih model MLP
3. Menguji model MLP
4. Hasil evaluasi model MLP dengan RMSE, MAE, dan MAPE
5. Visualisasi hasil prediksi dari model MLP terhadap nilai aktual

1. Membuat arsitektur model
"""

# Flatten the input for MLP
X_train_mlp = X_train.reshape((X_train.shape[0], X_train.shape[1] * X_train.shape[2]))
X_test_mlp = X_test.reshape((X_test.shape[0], X_test.shape[1] * X_test.shape[2]))

model_mlp = Sequential([
  Dense(100, input_shape=(lookback,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),
  Dropout(0.2),
  Dense(50, activation='relu'),
  Dropout(0.2),
  BatchNormalization(),
  Dense(1)
])
model_mlp.summary()

"""2. Fungsi callback untuk menghentikan proses pelatihan ketika model mencapai akurasi tertinggi"""

# Callback
callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
            tf.keras.callbacks.ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)]

"""3. Melatih model"""

model_mlp.compile(loss='mae', optimizer='adam', metrics=["mae"])
history_mlp = model_mlp.fit(X_train_mlp, y_train, epochs=100, callbacks=callback, batch_size=32, validation_split=0.1, verbose=1)

"""#### Model Evaluation
Di tahap ini, model yang telah dilatih akan di uji dengan data uji. Dari hasil pengujian, selanjutnya model dievaluasi dengan menggunakan beberapa metrik evaluasi, yaitu RMSE, MAE, dan MAPE

Prediction<br>
Menguji hasil pelatihan model dengan data uji
"""

# Predict on test set
pred_mlp_scaled = model_mlp.predict(X_test_mlp)

# Inverse-transform the predictions and actual values
pred_mlp_2d = pred_mlp_scaled.reshape(-1, 1)

y_test_unscaled = scaler.inverse_transform(y_test_2d)  # Reuse y_test_unscaled from LSTM
pred_mlp_unscaled = scaler.inverse_transform(pred_mlp_2d)

# Flatten for consistency
pred_mlp_unscaled = pred_mlp_unscaled.flatten()

"""Evaluation<br>
Mengukur hasil uji model dengan metrik RMSE, MAE, dan MAPE
"""

rmse_mlp_unscaled = np.sqrt(mean_squared_error(y_test_unscaled, pred_mlp_unscaled))
mae_mlp_unscaled = mean_absolute_error(y_test_unscaled, pred_mlp_unscaled)
mape_mlp_unscaled = mean_absolute_percentage_error(y_test_unscaled, pred_mlp_unscaled) * 100
print(f"RMSE: {rmse_mlp_unscaled:.4f}")
print(f"MAE: {mae_mlp_unscaled:.4f}")
print(f"MAPE: {mape_mlp_unscaled:.4f}%")

"""Visualization<br>
Visualisasi hasil uji model terhadap nilai aktual
"""

plt.figure(figsize=(14, 6))
plt.plot(y_test_unscaled[:300], label="Actual Data (Close)")
plt.plot(pred_mlp_unscaled[:300], label="MLP Prediction", linestyle='--')
plt.title("MLP: Prediction vs Actual Data (Close)")
plt.xlabel("Time")
plt.ylabel("Close")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### Model Comparison
Hasil evaluasi dari kedua model kemudian dibandingkan untuk mengetahui mana yang lebih baik. Berikut adalah hasil evaluasi dari kedua model:

Membandingkan semua metrik yang digunakan untuk evaluasi kedua model
"""

# Gather all the metrics
metrics = pd.DataFrame({
	'metric': ['RMSE', 'MAE', 'MAPE (%)'],
 	'LSTM': [f"{rmse_lstm_unscaled:.4f}", f"{mae_lstm_unscaled:.4f}", f"{mape_lstm_unscaled:.4f}"],
  'MLP': [f"{rmse_mlp_unscaled:.4f}", f"{mae_mlp_unscaled:.4f}", f"{mape_mlp_unscaled:.4f}"],
})
metrics

"""Visualisasi perbandingan hasil pelatihan kedua model terhadap data aktual"""

# Visualize Actual vs Predicted for LSTM and MLP
plt.figure(figsize=(14, 6))

# Plot actual data (either LSTM or MLP true_close)
plt.plot(y_test_unscaled[:300], label="Actual Data (Close)", color='black', linestyle='-')

# Plot MLP predictions
plt.plot(pred_mlp_unscaled[:300], label="MLP Prediction", color='orange', linestyle='--')

# Plot LSTM predictions
plt.plot(pred_lstm_unscaled[:300], label="LSTM Prediction", color='blue', linestyle='--')

# Add labels, title, and legend
plt.title("LSTM vs MLP: Prediction vs Actual Data (Close)", fontsize=14)
plt.xlabel("Time", fontsize=12)
plt.ylabel("Close Price", fontsize=12)
plt.legend()
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()

"""## Forecasting
Di tahap ini, model yang sudah dilatih dan diuji, kemudian digunakan untuk melakukan prediksi pergerakan harga saham BBRI untuk 30 hari kedepan

### LSTM Model

Mempersiapkan data yang dibutuhkan untuk melakukan forecasting dengan model LSTM
"""

# Forecast future values
future_days = 30
last_sequence = data_scaled[-lookback:].reshape(1, lookback, 1)  # Shape for LSTM
future_forecast_lstm = []

# Iteratively predict future values
for _ in range(future_days):
    lstm_pred = model_lstm.predict(last_sequence)
    future_forecast_lstm.append(lstm_pred[0, 0])
    # Update sequence
    last_sequence = np.roll(last_sequence, -1, axis=1)
    last_sequence[0, -1, 0] = lstm_pred[0, 0]

# Inverse-transform the forecast
future_forecast_lstm_2d = np.array(future_forecast_lstm).reshape(-1, 1)
future_forecast_lstm_unscaled = scaler.inverse_transform(future_forecast_lstm_2d).flatten()

# Create future dates
last_date = pd.to_datetime(df_preprocessed.index[-1])
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_days, freq='B')

"""### MLP Model

Mempersiapkan data yang dibutuhkan untuk melakukan forecasting dengan model MLP
"""

# Forecast future values for MLP
last_sequence_mlp = data_scaled[-lookback:].reshape(1, -1)  # Shape for MLP
future_forecast_mlp = []

# Iteratively predict future values
for _ in range(future_days):
    mlp_pred = model_mlp.predict(last_sequence_mlp)
    future_forecast_mlp.append(mlp_pred[0, 0])
    # Update sequence
    last_sequence_mlp = np.roll(last_sequence_mlp, -1)
    last_sequence_mlp[0, -1] = mlp_pred[0, 0]

# Inverse-transform the forecast
future_forecast_mlp_2d = np.array(future_forecast_mlp).reshape(-1, 1)
future_forecast_mlp_unscaled = scaler.inverse_transform(future_forecast_mlp_2d).flatten()

"""Visualisasi hasil forecasting untuk 30 hari kedepan dari kedua model"""

# Plot historical data and forecasts
plt.figure(figsize=(14, 6))
plt.plot(df.index[-100:], df['Close'][-100:], label="Historical Close", color='black')
plt.plot(future_dates, future_forecast_lstm_unscaled, label="LSTM Forecast", color='blue', linestyle='--')
plt.plot(future_dates, future_forecast_mlp_unscaled, label="MLP Forecast", color='orange', linestyle='--')
plt.title("LSTM vs MLP: 30-Day Forecast of BBRI Stock Price", fontsize=14)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Close Price", fontsize=12)
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()